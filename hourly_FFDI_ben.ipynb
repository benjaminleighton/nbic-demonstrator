{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBIC Workflow Provena Toy Example - Redux\n",
    "\n",
    "This reworks the original NBIC Workflow Provena Toy Example embracing a number of principals for capturing provenance in use cases where users may not have time or knowledge to build and manage detailed provenance records.\n",
    "\n",
    "It relies on nbic.py a very rough prototype and mock of utilities for automating provenance record creation. Fundamental is the create_or_fetch pattern which proposes that, often, there is enough information to create a dataset_template, dataset, model_run_template and model run from information implicit in user activities or through a very minimal user input. The create_or_fetch pattern, when fully implemented would fuzzy search existing entities and provide suggestions allowing users to select an existing entities, or, when no match is found, automatically create the missing entity.\n",
    "\n",
    "In leui of fully implementing the create_or_fetch pattern a number of resources have been created directly in the provena interface for use in mocks in this workflow for example the entity https://hdl.handle.net/10378.1/1741058 represents a generic dataset template that with a display name of wind and a simple deferred resource with a key of \"path\". It would be possible to create this resource from a call like p.register_input_dataset('s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr', 'wind_speed') furthermore this corresponding dataset record also created for use in mocks at https://hdl.handle.net/10378.1/1740705 could have been created automatically with minimal metadata using the S3 path passed in the register_input_dataset call. \n",
    "\n",
    "Similarly model run workflow templates and model runs themselves can be automatically generated. In nbic.py model_run_payload best demonstrates the automatic creation of a records from minimal user input.\n",
    "\n",
    "All functionality is encapsulated in a provenance object that stores inputs and outputs for later use when model run templates and model run records are required to be generated. The provenance object also captures a default start and end time and would, if fully implemented, guess the organisation and person associated with the workflow.\n",
    "\n",
    "Quality of provenance records generated through this workflow may vary. There are numerous possibilities to improve these  records if that is required. Dataset, dataset template, model run workflow templates and model run records could all be edited post-hoc if Provena allows this. Further enhancements might include identifying these records using automated annotations as \"draft\" and filtering them until they are improved or reviewed by the creator or a provenance manager. Quick capture of provenance is important because in many cases important data products are produced under pressure, many important variations on workflows maybe lost because provenance overhead maybe too high and science experts may struggle to comprehend and implement provenance detail requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is a small helper class which provides a config object for validation and\n",
    "# a loader function\n",
    "import workflow_config\n",
    "\n",
    "# this contains helpers for interacting with the registry\n",
    "import registry\n",
    "\n",
    "# This is a helper function for managing authentication with Provena\n",
    "import mdsisclienttools.auth.TokenManager as ProvenaAuth\n",
    "\n",
    "\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbic\n",
    "from nbic import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Provenance Object, creation of this starts a timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "p = Provenance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No storage or object provided, using default location: .tokens.json.\n",
      "Using storage type: FILE.\n",
      "Using DEVICE auth flow.\n",
      "Attempting to generate authorisation tokens.\n",
      "\n",
      "Looking for existing tokens in local storage.\n",
      "\n",
      "Validating found tokens\n",
      "\n",
      "Trying to use found tokens to refresh the access token.\n",
      "\n",
      "Tokens found in storage but they are not valid.\n",
      "\n",
      "Initiating device auth flow to generate access and refresh tokens.\n",
      "\n",
      "Decoding response\n",
      "\n",
      "Please authorise using the following endpoint.\n",
      "\n",
      "Verification URL: https://auth.dev.provena.nbic.cloud/auth/realms/provena/device?user_code=UFKT-HWLU\n",
      "User Code: UFKT-HWLU\n",
      "\u001b[?1l\u001b>4;1H\u001b[2J\u001b[?47l\u001b8TPS connection to auth.dev.provena.nbic.cloud\u001b[m\u001b[m                   \u001b[22;39H\u001b[m\u001b[m                           \u001b[2;1H                                                                                \u001b[3;1H                                                                                \u001b[4;1H                                                                                \u001b[5;1H                                                                                \u001b[6;1H                                                                                \u001b[7;1H                                                                                \u001b[8;1H                                                                                \u001b[9;1H                                                                                \u001b[10;1H                                                                                \u001b[11;1H                                                                                \u001b[12;1H                                                                                \u001b[13;1H                                                                                \u001b[14;1H                                                                                \u001b[15;1H                                                                                \u001b[16;1H                                                                                \u001b[17;1H                                                                                \u001b[18;1H                                                                                \u001b[19;1H                                                                                \u001b[20;1H                                                                                \u001b[21;1H                                                                                \u001b[22;1H                                                                                \u001b[23;1H                                                                                \u001b[24;1H                                                                              \u001b[4h\u001b[37m\u001b[40m \u001b[4l\u001b[H\u001b[m\u001b[m\u001b[37m\u001b[40m\u001b[m\u001b[m\u001b[21B\u001b[33m\u001b[44m\u001b[1mGetting https://auth.dev.provena.nbic.cloud/auth/realms/provena/device?user_cod \u001b[22;80H\u001b[m\u001b[m\n",
      "Awaiting completion\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Authorization\n",
    "provena_auth = ProvenaAuth.DeviceFlowManager(\n",
    "    stage=stage,\n",
    "    keycloak_endpoint=kc_endpoint\n",
    ")\n",
    "\n",
    "# expose the get auth function which is used for provena methods \n",
    "get_auth = provena_auth.get_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Mocks - we shouldn'nt need config at this point in a full implementation\n",
    "config_path = \"./configs/example_workflow.json\"\n",
    "config = workflow_config.load_config(path=config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# For Mocks - we shouldn'nt need config at this point in a full implementation\n",
    "nbic.config = config\n",
    "nbic.registry = registry\n",
    "nbic.get_auth = get_auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal wrapping of paths to register inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from registry, id: 10378.1/1740705...\n",
      "Fetching from registry, id: 10378.1/1741057...\n",
      "Fetching from registry, id: 10378.1/1740705...\n",
      "Fetching from registry, id: 10378.1/1741060...\n",
      "Fetching from registry, id: 10378.1/1740705...\n",
      "Fetching from registry, id: 10378.1/1741058...\n",
      "Fetching from registry, id: 10378.1/1740705...\n",
      "Fetching from registry, id: 10378.1/1741059...\n"
     ]
    }
   ],
   "source": [
    "## The provenance object register_input_dataset either finds and retrieves existing dataset records and dataset template records or creates them\n",
    "## In the current implementation this happens immediately but we could delay creation till model run registration if we didn't want to clog up the workflow\n",
    "temperature_path = p.register_input_dataset('s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr', 'temperature')\n",
    "humidity_path = p.register_input_dataset('s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr', 'humidity')\n",
    "wind_speed_path = p.register_input_dataset('s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr', 'wind_speed')\n",
    "mc_adf_path = p.register_input_dataset('s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr', 'mc_adf_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our fake model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from registry, id: 10378.1/1740705...\n",
      "Fetching from registry, id: 10378.1/1741061...\n"
     ]
    }
   ],
   "source": [
    "##This is similar to what was happening in the original notebook except we register an output similar to the inputs above \n",
    "temperature = xr.open_zarr(temperature_path)\n",
    "humidity_path = xr.open_zarr(temperature_path)\n",
    "wind_speed_path = xr.open_zarr(temperature_path)\n",
    "mc_adf_path = xr.open_zarr(temperature_path)\n",
    "\n",
    "def fake_model(temperature: int, humidity: int, wind_speed : int, mc_adf: int) -> int:\n",
    "    # this model does some heavy lifting and takes 10 seconds to finish \n",
    "    time.sleep(1)     \n",
    "    return xr\n",
    "\n",
    "# run the model \n",
    "fake_model_output = fake_model(\n",
    "    temperature=temperature,\n",
    "    humidity=humidity_path,\n",
    "    wind_speed=wind_speed_path,\n",
    "    mc_adf=mc_adf_path\n",
    ")\n",
    "\n",
    "fake_model_output_path = p.register_output_dataset(\"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_FFDI.zarr\", 'ffdi')\n",
    "fake_model_output.to_zarr(fake_model_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment if you want to see the template, internally the template would be fetched or created from inputs/outputs\n",
    "# p._create_or_fetch_workflow_template_record()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the model run record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the model run record passing only description in \n",
    "model_run_payload = p.model_run_payload(\"hourly FFDI\")\n",
    "model_run_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Don't validate stuff \n",
    "# if the items aren't valid presumably we would want to register them with a warning this\n",
    "# workflow is valid by definition\n",
    "\n",
    "#if not valid:\n",
    "#    print(\"FAILED VALIDATION\")\n",
    "#    raise Exception(\"Workflow config validation exception occurred. See output above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model run\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': '10378.1/1741747',\n",
       " 'prov_json': '{\"prefix\": {\"default\": \"http://hdl.handle.net/\"}, \"activity\": {\"10378.1/1741747\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ACTIVITY\", \"item_subtype\": \"MODEL_RUN\"}}, \"entity\": {\"10378.1/1740705\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"DATASET\"}, \"10378.1/1741046\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"MODEL_RUN_WORKFLOW_TEMPLATE\", \"prov:type\": {\"$\": \"prov:Collection\", \"type\": \"prov:QUALIFIED_NAME\"}}, \"10378.1/1741057\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"DATASET_TEMPLATE\"}, \"10378.1/1741060\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"DATASET_TEMPLATE\"}, \"10378.1/1741058\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"DATASET_TEMPLATE\"}, \"10378.1/1741059\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"DATASET_TEMPLATE\"}, \"10378.1/1741061\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"DATASET_TEMPLATE\"}, \"10378.1/1741045\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"ENTITY\", \"item_subtype\": \"MODEL\"}}, \"agent\": {\"10378.1/1740702\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"AGENT\", \"item_subtype\": \"PERSON\"}, \"10378.1/1727883\": {\"model_run/10378.1/1741747\": true, \"item_category\": \"AGENT\", \"item_subtype\": \"ORGANISATION\"}}, \"used\": {\"_:id1\": [{\"prov:activity\": \"10378.1/1741747\", \"prov:entity\": \"10378.1/1740705\"}, {\"prov:activity\": \"10378.1/1741747\", \"prov:entity\": \"10378.1/1740705\"}, {\"prov:activity\": \"10378.1/1741747\", \"prov:entity\": \"10378.1/1740705\"}, {\"prov:activity\": \"10378.1/1741747\", \"prov:entity\": \"10378.1/1740705\"}], \"_:id3\": {\"prov:activity\": \"10378.1/1741747\", \"prov:entity\": \"10378.1/1741045\"}, \"_:id4\": {\"prov:activity\": \"10378.1/1741747\", \"prov:entity\": \"10378.1/1741046\"}}, \"wasGeneratedBy\": {\"_:id2\": {\"prov:entity\": \"10378.1/1740705\", \"prov:activity\": \"10378.1/1741747\"}}, \"wasAssociatedWith\": {\"_:id5\": {\"prov:activity\": \"10378.1/1741747\", \"prov:agent\": \"10378.1/1740702\"}, \"_:id6\": {\"prov:activity\": \"10378.1/1741747\", \"prov:agent\": \"10378.1/1727883\"}}, \"wasAttributedTo\": {\"_:id7\": {\"prov:entity\": \"10378.1/1740705\", \"prov:agent\": \"10378.1/1740702\"}}, \"hadMember\": {\"_:id8\": {\"prov:collection\": \"10378.1/1741046\", \"prov:entity\": \"10378.1/1741057\"}, \"_:id10\": {\"prov:collection\": \"10378.1/1741046\", \"prov:entity\": \"10378.1/1741060\"}, \"_:id12\": {\"prov:collection\": \"10378.1/1741046\", \"prov:entity\": \"10378.1/1741058\"}, \"_:id14\": {\"prov:collection\": \"10378.1/1741046\", \"prov:entity\": \"10378.1/1741059\"}, \"_:id16\": {\"prov:collection\": \"10378.1/1741046\", \"prov:entity\": \"10378.1/1741061\"}, \"_:id18\": {\"prov:collection\": \"10378.1/1741046\", \"prov:entity\": \"10378.1/1741045\"}}, \"wasInfluencedBy\": {\"_:id9\": {\"prov:influencee\": \"10378.1/1740705\", \"prov:influencer\": \"10378.1/1741057\"}, \"_:id11\": {\"prov:influencee\": \"10378.1/1740705\", \"prov:influencer\": \"10378.1/1741060\"}, \"_:id13\": {\"prov:influencee\": \"10378.1/1740705\", \"prov:influencer\": \"10378.1/1741058\"}, \"_:id15\": {\"prov:influencee\": \"10378.1/1740705\", \"prov:influencer\": \"10378.1/1741059\"}, \"_:id17\": {\"prov:influencee\": \"10378.1/1740705\", \"prov:influencer\": \"10378.1/1741061\"}}}',\n",
       " 'record': {'workflow_template_id': '10378.1/1741046',\n",
       "  'inputs': [{'dataset_template_id': '10378.1/1741057',\n",
       "    'dataset_id': '10378.1/1740705',\n",
       "    'dataset_type': 'DATA_STORE',\n",
       "    'resources': {'path': 's3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr'}},\n",
       "   {'dataset_template_id': '10378.1/1741060',\n",
       "    'dataset_id': '10378.1/1740705',\n",
       "    'dataset_type': 'DATA_STORE',\n",
       "    'resources': {'path': 's3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr'}},\n",
       "   {'dataset_template_id': '10378.1/1741058',\n",
       "    'dataset_id': '10378.1/1740705',\n",
       "    'dataset_type': 'DATA_STORE',\n",
       "    'resources': {'path': 's3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr'}},\n",
       "   {'dataset_template_id': '10378.1/1741059',\n",
       "    'dataset_id': '10378.1/1740705',\n",
       "    'dataset_type': 'DATA_STORE',\n",
       "    'resources': {'path': 's3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr'}}],\n",
       "  'outputs': [{'dataset_template_id': '10378.1/1741061',\n",
       "    'dataset_id': '10378.1/1740705',\n",
       "    'dataset_type': 'DATA_STORE',\n",
       "    'resources': {'path': 's3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr'}}],\n",
       "  'annotations': None,\n",
       "  'description': 'hourly FFDI',\n",
       "  'associations': {'modeller_id': '10378.1/1740702',\n",
       "   'requesting_organisation_id': '10378.1/1727883'},\n",
       "  'start_time': 1692938621,\n",
       "  'end_time': 1692938626}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Registering the model run \n",
    "endpoint = provenance_endpoint + \"/model_run/register_complete\"\n",
    "payload = model_run_payload\n",
    "\n",
    "# send off request\n",
    "print(\"Registering model run\")\n",
    "response = requests.post(url=endpoint, json=payload, auth=get_auth())\n",
    "\n",
    "# use helper function to check response\n",
    "registry.check_response(response=response, status_check=True)\n",
    "\n",
    "response_content = response.json()\n",
    "method_two_record_info = response_content[\"record_info\"]\n",
    "method_two_record_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prov",
   "language": "python",
   "name": "prov"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
