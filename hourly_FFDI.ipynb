{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NBIC Workflow Provena Toy Example\n",
    "\n",
    "This relies on some pre-registered components and is intended to show an example provenance enabled workflow by integrating with the provena APIs. \n",
    "\n",
    "The actual computation/validation has been stripped from the source notebook - but hopefully it will be clear where this can be reintroduced"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provena workflow configuration setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a small helper class which provides a config object for validation and\n",
    "# a loader function\n",
    "import workflow_config\n",
    "\n",
    "# this contains helpers for interacting with the registry\n",
    "import registry\n",
    "\n",
    "# This is a helper function for managing authentication with Provena\n",
    "import mdsisclienttools.auth.TokenManager as ProvenaAuth\n",
    "\n",
    "\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "import time\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provena config\n",
    "stage = \"DEV\"\n",
    "kc_endpoint = \"https://auth.dev.rrap-is.com/auth/realms/rrap\"\n",
    "registry_endpoint = \"https://registry-api.dev.rrap-is.com\"\n",
    "provenance_endpoint = \"https://prov-api.dev.rrap-is.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No storage or object provided, using default location: .tokens.json.\n",
      "Using storage type: FILE.\n",
      "Using DEVICE auth flow.\n",
      "Attempting to generate authorisation tokens.\n",
      "\n",
      "Looking for existing tokens in local storage.\n",
      "\n",
      "Validating found tokens\n",
      "\n",
      "Trying to use found tokens to refresh the access token.\n",
      "\n",
      "Token refresh successful.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sets up auth connections - could potentially open browser window if not signed\n",
    "# in recently - caches in .tokens.json - ensure this is included in gitignore\n",
    "provena_auth = ProvenaAuth.DeviceFlowManager(\n",
    "    stage=stage,\n",
    "    keycloak_endpoint=kc_endpoint\n",
    ")\n",
    "\n",
    "# expose the get auth function which is used for provena methods \n",
    "get_auth = provena_auth.get_auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inputs\": {\n",
      "    \"hourly_temperature\": \"10378.1/1709248\",\n",
      "    \"hourly_temperature_template\": \"10378.1/1709254\",\n",
      "    \"relative_humidity\": \"10378.1/1709249\",\n",
      "    \"relative_humidity_template\": \"10378.1/1709255\",\n",
      "    \"wind_speed\": \"10378.1/1709251\",\n",
      "    \"wind_speed_template\": \"10378.1/1709256\",\n",
      "    \"daily_mc_adf\": \"10378.1/1709252\",\n",
      "    \"daily_mc_adf_template\": \"10378.1/1709257\"\n",
      "  },\n",
      "  \"outputs\": {\n",
      "    \"hourly_ffdi\": \"10378.1/1709260\",\n",
      "    \"hourly_ffdi_template\": \"10378.1/1709258\"\n",
      "  },\n",
      "  \"associations\": {\n",
      "    \"person\": \"10378.1/1709236\",\n",
      "    \"organisation\": \"10378.1/1709247\"\n",
      "  },\n",
      "  \"workflow_configuration\": {\n",
      "    \"workflow_template\": \"10378.1/1709259\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Start by loading the config from the specified path \n",
    "\n",
    "# NOTE this could change from run to run - this holds all information required to run this model\n",
    "config_path = \"configs/example_workflow.json\"\n",
    "config = workflow_config.load_config(path=config_path)\n",
    "config.pprint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating registered Provena entities in config\n",
      "Validating registered input datasets...\n",
      "Fetching from registry, id: 10378.1/1709248...\n",
      "Fetching from registry, id: 10378.1/1709249...\n",
      "Fetching from registry, id: 10378.1/1709251...\n",
      "Fetching from registry, id: 10378.1/1709252...\n",
      "Fetching from registry, id: 10378.1/1709254...\n",
      "Fetching from registry, id: 10378.1/1709255...\n",
      "Fetching from registry, id: 10378.1/1709256...\n",
      "Fetching from registry, id: 10378.1/1709257...\n",
      "Validating registered output datasets...\n",
      "Fetching from registry, id: 10378.1/1709260...\n",
      "Fetching from registry, id: 10378.1/1709258...\n",
      "Validating registered associations...\n",
      "Fetching from registry, id: 10378.1/1709236...\n",
      "Fetching from registry, id: 10378.1/1709247...\n",
      "Validating registered associations...\n",
      "Fetching from registry, id: 10378.1/1709259...\n",
      "Validation successful...\n"
     ]
    }
   ],
   "source": [
    "# let's validate the workflow config - this fetches ALL items referenced in the\n",
    "# workflow json to ensure the items are valid \n",
    "valid = config.validate_entities(registry_endpoint=registry_endpoint, auth=get_auth)\n",
    "\n",
    "if not valid:\n",
    "    print(\"FAILED VALIDATION\")\n",
    "    raise Exception(\"Workflow config validation exception occurred. See output above.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model run integration\n",
    "Now that the validation of the workflow configuration (incl. registered entitites) is complete - we can move into the example of running the model against this configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data paths"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider how data can be loaded. \n",
    "\n",
    "This example is straight from the notebook: \n",
    "\n",
    "```python\n",
    "temperature = xr.open_zarr(nbic.catalog_s3_stage1.weather.projected.to_path('AU_hourly_temperature_C.zarr'), chunks='auto')\n",
    "```\n",
    "\n",
    "In this case we have a mechanism to reference the variable part of the data path, but hardcode the zarr file path. \n",
    "\n",
    "We could continue to operate in this manner, or we could utilise the external reposited path metadata in the registered dataset instead. I will demonstrate this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from registry, id: 10378.1/1709248...\n",
      "{\n",
      "  \"display_name\": \"NBIC Hourly Temperature\",\n",
      "  \"collection_format\": {\n",
      "    \"associations\": {\n",
      "      \"organisation_id\": \"10378.1/1709247\"\n",
      "    },\n",
      "    \"dataset_info\": {\n",
      "      \"name\": \"NBIC Hourly Temperature\",\n",
      "      \"description\": \"Used in the example HourlyFFDI workflow. \\n\\nContains the hourly temperature. Hosted on external storage.\",\n",
      "      \"access_info\": {\n",
      "        \"reposited\": false,\n",
      "        \"uri\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr\",\n",
      "        \"description\": \"This is hosted on the EASI platform in the NBIC stage one bucket. Contains a zarr file used for processing.\"\n",
      "      },\n",
      "      \"publisher_id\": \"10378.1/1709247\",\n",
      "      \"created_date\": \"2023-06-06\",\n",
      "      \"published_date\": \"2023-06-06\",\n",
      "      \"license\": \"https://gbrrestoration.github.io/rrap-mds-knowledge-hub/information-system/licenses.html#copyright-all-rights-reserved-\",\n",
      "      \"preferred_citation\": null,\n",
      "      \"keywords\": [\n",
      "        \"NBIC\",\n",
      "        \"Hourly\",\n",
      "        \"FFDI\",\n",
      "        \"Temperature\"\n",
      "      ],\n",
      "      \"version\": null\n",
      "    },\n",
      "    \"approvals\": {\n",
      "      \"ethics_registration\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      },\n",
      "      \"ethics_access\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      },\n",
      "      \"indigenous_knowledge\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      },\n",
      "      \"export_controls\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"s3\": {\n",
      "    \"bucket_name\": \"restored-dev-dev-rrap-storage-bucket-11102022-11102022\",\n",
      "    \"path\": \"datasets/10378-1-1709248/\",\n",
      "    \"s3_uri\": \"s3://restored-dev-dev-rrap-storage-bucket-11102022-11102022/datasets/10378-1-1709248/\"\n",
      "  },\n",
      "  \"history\": [\n",
      "    {\n",
      "      \"id\": 0,\n",
      "      \"timestamp\": 1686008038,\n",
      "      \"reason\": \"Initial record creation\",\n",
      "      \"username\": \"peter\",\n",
      "      \"item\": {\n",
      "        \"display_name\": \"NBIC Hourly Temperature\",\n",
      "        \"collection_format\": {\n",
      "          \"associations\": {\n",
      "            \"organisation_id\": \"10378.1/1709247\"\n",
      "          },\n",
      "          \"dataset_info\": {\n",
      "            \"name\": \"NBIC Hourly Temperature\",\n",
      "            \"description\": \"Used in the example HourlyFFDI workflow. \\n\\nContains the hourly temperature. Hosted on external storage.\",\n",
      "            \"access_info\": {\n",
      "              \"reposited\": false,\n",
      "              \"uri\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr\",\n",
      "              \"description\": \"This is hosted on the EASI platform in the NBIC stage one bucket. Contains a zarr file used for processing.\"\n",
      "            },\n",
      "            \"publisher_id\": \"10378.1/1709247\",\n",
      "            \"created_date\": \"2023-06-06\",\n",
      "            \"published_date\": \"2023-06-06\",\n",
      "            \"license\": \"https://gbrrestoration.github.io/rrap-mds-knowledge-hub/information-system/licenses.html#copyright-all-rights-reserved-\",\n",
      "            \"preferred_citation\": null,\n",
      "            \"keywords\": [\n",
      "              \"NBIC\",\n",
      "              \"Hourly\",\n",
      "              \"FFDI\",\n",
      "              \"Temperature\"\n",
      "            ],\n",
      "            \"version\": null\n",
      "          },\n",
      "          \"approvals\": {\n",
      "            \"ethics_registration\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            },\n",
      "            \"ethics_access\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            },\n",
      "            \"indigenous_knowledge\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            },\n",
      "            \"export_controls\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"s3\": {\n",
      "          \"bucket_name\": \"restored-dev-dev-rrap-storage-bucket-11102022-11102022\",\n",
      "          \"path\": \"datasets/10378-1-1709248/\",\n",
      "          \"s3_uri\": \"s3://restored-dev-dev-rrap-storage-bucket-11102022-11102022/datasets/10378-1-1709248/\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"id\": \"10378.1/1709248\",\n",
      "  \"owner_username\": \"peter\",\n",
      "  \"created_timestamp\": 1686008037,\n",
      "  \"updated_timestamp\": 1686008038,\n",
      "  \"item_category\": \"ENTITY\",\n",
      "  \"item_subtype\": \"DATASET\",\n",
      "  \"record_type\": \"COMPLETE_ITEM\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# let's establish the paths of the input from the dataset\n",
    "def pprint_json(content) -> None:\n",
    "    print(json.dumps(content,indent=2))\n",
    "\n",
    "# fetch the dataset \n",
    "ds_id = config.inputs.hourly_temperature\n",
    "fetched_ds = registry.fetch_dataset(registry_endpoint=registry_endpoint, id=ds_id, auth=get_auth())\n",
    "pprint_json(fetched_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr\n"
     ]
    }
   ],
   "source": [
    "# determine the external reposit path\n",
    "file_path = fetched_ds[\"collection_format\"][\"dataset_info\"][\"access_info\"][\"uri\"]\n",
    "print(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated above, it is possible to retrieve the associated file path from the registered Dataset (assuming this info was included at registration time). Or the existing file path mechanism could continue being used.\n",
    "\n",
    "A similar approach works for the other inputs. Shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from registry, id: 10378.1/1709248...\n",
      "Fetching from registry, id: 10378.1/1709249...\n",
      "Fetching from registry, id: 10378.1/1709251...\n",
      "Fetching from registry, id: 10378.1/1709252...\n",
      "{\n",
      "  \"Temperature: \": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr\",\n",
      "  \"Humidity: \": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_relative_humidity_percent.zarr\",\n",
      "  \"Wind Speed: \": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/baseline/AU_hourly_wind_speed_mps_updated_220224_corrected.zarr\",\n",
      "  \"Mc ADF: \": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_daily_McADF_improved_uncapped.zarr\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def fetch_and_path(id: str):\n",
    "    dataset = registry.fetch_dataset(registry_endpoint=registry_endpoint, id=id, auth=get_auth())\n",
    "    path = dataset[\"collection_format\"][\"dataset_info\"][\"access_info\"][\"uri\"]\n",
    "    return dataset, path\n",
    "\n",
    "# temperature\n",
    "temperature_ds, temperature_path = fetch_and_path(id=config.inputs.hourly_temperature)\n",
    "\n",
    "# humidity\n",
    "humidity_ds, humidity_path = fetch_and_path(id=config.inputs.relative_humidity)\n",
    "\n",
    "# wind speed\n",
    "wind_speed_ds, wind_speed_path = fetch_and_path(id=config.inputs.wind_speed)\n",
    "\n",
    "# mc adf\n",
    "mc_adf_ds, mc_adf_path = fetch_and_path(id=config.inputs.daily_mc_adf)\n",
    "\n",
    "pprint_json({\n",
    "   \"Temperature: \" : temperature_path,\n",
    "   \"Humidity: \" : humidity_path,\n",
    "   \"Wind Speed: \" : wind_speed_path,\n",
    "   \"Mc ADF: \" : mc_adf_path,\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if we wanted to use the data storage utilities of the Provena data store, we could register a reposited dataset, and use the dynamic credential generation to produce r or r/w credentials into that specific dataset."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our fake model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to pretend to produce some output from this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran fake hourly FFDI calculation, took 10 seconds.\n"
     ]
    }
   ],
   "source": [
    "def fake_data_fetch(path: str) -> int:\n",
    "    # This method would take the path and return the data\n",
    "    return 0\n",
    "\n",
    "fake_temperature = fake_data_fetch(temperature_path)\n",
    "fake_humidity = fake_data_fetch(humidity_path)\n",
    "fake_wind_speed = fake_data_fetch(wind_speed_path)\n",
    "fake_mc_adf = fake_data_fetch(mc_adf_path)\n",
    "\n",
    "def fake_model(temperature: int, humidity: int, wind_speed : int, mc_adf: int) -> int:\n",
    "    # this model does some heavy lifting and takes 10 seconds to finish \n",
    "    time.sleep(10) \n",
    "    \n",
    "    return 0\n",
    "\n",
    "# let's run our model with the inputs \n",
    "\n",
    "# start timer\n",
    "start_time = int(time.time())\n",
    "\n",
    "# run the model \n",
    "fake_model_output = fake_model(\n",
    "    temperature=fake_temperature,\n",
    "    humidity=fake_humidity,\n",
    "    wind_speed=fake_wind_speed,\n",
    "    mc_adf=fake_mc_adf\n",
    ")\n",
    "\n",
    "end_time = int(time.time())\n",
    "\n",
    "print(f\"Ran fake hourly FFDI calculation, took {end_time - start_time} seconds.\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have ran the toy model, let's register a provenance record which records the model run, the inputs used, and the outputs produced.\n",
    "\n",
    "We need to think more about the output. \n",
    "\n",
    "There are two primary ways that Provena supports registering the results of a model run. \n",
    "\n",
    "1. Dynamically register a new Dataset and link to this dataset. This is the _preferred_ method as it creates a clear causal chain between the model and the output dataset.\n",
    "2. Use a deferred or defined resource in an output dataset template to register the outputs into an existing dataset. E.g. overwrite an existing file or contribute new files to an existing dataset. This method produces less structurally clear provenance chains and may obfuscate the history of data (if overwriting).\n",
    "\n",
    "We will show both methods. Method 2) is more closely aligned with the existing data path workflow in NBIC.\n",
    "\n",
    "Model runs satisfy the following JSON schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"workflow_template_id\": \"string\",\n",
    "  \"inputs\": [\n",
    "    {\n",
    "      \"dataset_template_id\": \"string\",\n",
    "      \"dataset_id\": \"string\",\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"additionalProp1\": \"string\",\n",
    "        \"additionalProp2\": \"string\",\n",
    "        \"additionalProp3\": \"string\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"outputs\": [\n",
    "    {\n",
    "      \"dataset_template_id\": \"string\",\n",
    "      \"dataset_id\": \"string\",\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"additionalProp1\": \"string\",\n",
    "        \"additionalProp2\": \"string\",\n",
    "        \"additionalProp3\": \"string\"\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"annotations\": {\n",
    "    \"additionalProp1\": \"string\",\n",
    "    \"additionalProp2\": \"string\",\n",
    "    \"additionalProp3\": \"string\"\n",
    "  },\n",
    "  \"description\": \"string\",\n",
    "  \"associations\": {\n",
    "    \"modeller_id\": \"string\",\n",
    "    \"requesting_organisation_id\": \"string\"\n",
    "  },\n",
    "  \"start_time\": 0,\n",
    "  \"end_time\": 0\n",
    "}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overwrite an existing output at a specified path\n",
    "\n",
    "Let's start with method 2) and overwrite a specified output. This dataset is pre-registered and is included in our config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from registry, id: 10378.1/1709260...\n",
      "{\n",
      "  \"display_name\": \"NBIC Daily FFDI Preregistered Output\",\n",
      "  \"collection_format\": {\n",
      "    \"associations\": {\n",
      "      \"organisation_id\": \"10378.1/1709247\"\n",
      "    },\n",
      "    \"dataset_info\": {\n",
      "      \"name\": \"NBIC Daily FFDI Preregistered Output\",\n",
      "      \"description\": \"Used in the example HourlyFFDI workflow. \\n\\nThis contains a reference to the preregistered output. Supports overwritten workflow style where the output of the model overwrites an existing resource.\",\n",
      "      \"access_info\": {\n",
      "        \"reposited\": false,\n",
      "        \"uri\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_FFDI.zarr\",\n",
      "        \"description\": \"This is hosted on the EASI platform in the NBIC stage one bucket. Contains a zarr file which is the output of Hourly FFDI workflow.\"\n",
      "      },\n",
      "      \"publisher_id\": \"10378.1/1709247\",\n",
      "      \"created_date\": \"2023-06-06\",\n",
      "      \"published_date\": \"2023-06-06\",\n",
      "      \"license\": \"https://gbrrestoration.github.io/rrap-mds-knowledge-hub/information-system/licenses.html#copyright-all-rights-reserved-\",\n",
      "      \"preferred_citation\": null,\n",
      "      \"keywords\": [\n",
      "        \"NBIC\",\n",
      "        \"Hourly\",\n",
      "        \"FFDI\"\n",
      "      ],\n",
      "      \"version\": null\n",
      "    },\n",
      "    \"approvals\": {\n",
      "      \"ethics_registration\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      },\n",
      "      \"ethics_access\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      },\n",
      "      \"indigenous_knowledge\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      },\n",
      "      \"export_controls\": {\n",
      "        \"relevant\": false,\n",
      "        \"obtained\": false\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"s3\": {\n",
      "    \"bucket_name\": \"restored-dev-dev-rrap-storage-bucket-11102022-11102022\",\n",
      "    \"path\": \"datasets/10378-1-1709260/\",\n",
      "    \"s3_uri\": \"s3://restored-dev-dev-rrap-storage-bucket-11102022-11102022/datasets/10378-1-1709260/\"\n",
      "  },\n",
      "  \"history\": [\n",
      "    {\n",
      "      \"id\": 0,\n",
      "      \"timestamp\": 1686021032,\n",
      "      \"reason\": \"Initial record creation\",\n",
      "      \"username\": \"peter\",\n",
      "      \"item\": {\n",
      "        \"display_name\": \"NBIC Daily FFDI Preregistered Output\",\n",
      "        \"collection_format\": {\n",
      "          \"associations\": {\n",
      "            \"organisation_id\": \"10378.1/1709247\"\n",
      "          },\n",
      "          \"dataset_info\": {\n",
      "            \"name\": \"NBIC Daily FFDI Preregistered Output\",\n",
      "            \"description\": \"Used in the example HourlyFFDI workflow. \\n\\nThis contains a reference to the preregistered output. Supports overwritten workflow style where the output of the model overwrites an existing resource.\",\n",
      "            \"access_info\": {\n",
      "              \"reposited\": false,\n",
      "              \"uri\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_FFDI.zarr\",\n",
      "              \"description\": \"This is hosted on the EASI platform in the NBIC stage one bucket. Contains a zarr file which is the output of Hourly FFDI workflow.\"\n",
      "            },\n",
      "            \"publisher_id\": \"10378.1/1709247\",\n",
      "            \"created_date\": \"2023-06-06\",\n",
      "            \"published_date\": \"2023-06-06\",\n",
      "            \"license\": \"https://gbrrestoration.github.io/rrap-mds-knowledge-hub/information-system/licenses.html#copyright-all-rights-reserved-\",\n",
      "            \"preferred_citation\": null,\n",
      "            \"keywords\": [\n",
      "              \"NBIC\",\n",
      "              \"Hourly\",\n",
      "              \"FFDI\"\n",
      "            ],\n",
      "            \"version\": null\n",
      "          },\n",
      "          \"approvals\": {\n",
      "            \"ethics_registration\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            },\n",
      "            \"ethics_access\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            },\n",
      "            \"indigenous_knowledge\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            },\n",
      "            \"export_controls\": {\n",
      "              \"relevant\": false,\n",
      "              \"obtained\": false\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"s3\": {\n",
      "          \"bucket_name\": \"restored-dev-dev-rrap-storage-bucket-11102022-11102022\",\n",
      "          \"path\": \"datasets/10378-1-1709260/\",\n",
      "          \"s3_uri\": \"s3://restored-dev-dev-rrap-storage-bucket-11102022-11102022/datasets/10378-1-1709260/\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"id\": \"10378.1/1709260\",\n",
      "  \"owner_username\": \"peter\",\n",
      "  \"created_timestamp\": 1686021031,\n",
      "  \"updated_timestamp\": 1686021032,\n",
      "  \"item_category\": \"ENTITY\",\n",
      "  \"item_subtype\": \"DATASET\",\n",
      "  \"record_type\": \"COMPLETE_ITEM\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "### Overwrite existing output\n",
    "\n",
    "output_dataset_id = config.outputs.hourly_ffdi\n",
    "\n",
    "# we can resolve the path using the same approach as above, or using existing\n",
    "# NBIC path structure\n",
    "\n",
    "output_ds, output_path =fetch_and_path(id=output_dataset_id)\n",
    "\n",
    "pprint_json(output_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model run payload \n",
    "model_run_payload = {\n",
    "  # This specifies the workflow template we are using \n",
    "  \"workflow_template_id\": config.workflow_configuration.workflow_template,\n",
    "  \n",
    "  # here we specify a dataset to match each template, and optionally any\n",
    "  # deferred resources\n",
    "  \"inputs\": [\n",
    "    # temperature\n",
    "    {\n",
    "      \"dataset_template_id\": config.inputs.hourly_temperature_template,\n",
    "      \"dataset_id\": config.inputs.hourly_temperature,\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"hourly_temperature_zarr\": temperature_path,\n",
    "      }\n",
    "    },\n",
    "    # humidity\n",
    "    {\n",
    "      \"dataset_template_id\": config.inputs.relative_humidity_template,\n",
    "      \"dataset_id\": config.inputs.relative_humidity,\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"relative_humidity_zarr\": humidity_path,\n",
    "      }\n",
    "    },\n",
    "    # wind speed\n",
    "    {\n",
    "      \"dataset_template_id\": config.inputs.wind_speed_template,\n",
    "      \"dataset_id\": config.inputs.wind_speed,\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"wind_speed_zarr\": wind_speed_path\n",
    "      }\n",
    "    },\n",
    "    # Mc ADF\n",
    "    {\n",
    "      \"dataset_template_id\": config.inputs.daily_mc_adf_template,\n",
    "      \"dataset_id\": config.inputs.daily_mc_adf,\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"mcadf_zarr\": mc_adf_path\n",
    "      }\n",
    "    },\n",
    "  ],\n",
    "  \"outputs\": [\n",
    "    # Hourly FFDI output\n",
    "    {\n",
    "      \"dataset_template_id\": config.outputs.hourly_ffdi_template,\n",
    "      \"dataset_id\": config.outputs.hourly_ffdi,\n",
    "      \"dataset_type\": \"DATA_STORE\",\n",
    "      \"resources\": {\n",
    "        \"hourly_ffdi_zarr\" : output_path\n",
    "      }\n",
    "    },\n",
    "  ],\n",
    "  \"description\": \"HourlyFFDI Workflow. NBIC example. This is an example of using the FFDI workflow to register into an existing dataset.\",\n",
    "  \"associations\": {\n",
    "    \"modeller_id\": config.associations.person,\n",
    "    \"requesting_organisation_id\": config.associations.organisation\n",
    "  },\n",
    "  \"start_time\": start_time, \n",
    "  \"end_time\": end_time\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model run\n",
      "Token validation failed due to error: Signature has expired.\n",
      "Refreshing using refresh token\n",
      "\n",
      "{\n",
      "  \"id\": \"10378.1/1709261\",\n",
      "  \"prov_json\": \"{\\\"prefix\\\": {\\\"default\\\": \\\"http://hdl.handle.net/\\\"}, \\\"activity\\\": {\\\"10378.1/1709261\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ACTIVITY\\\", \\\"item_subtype\\\": \\\"MODEL_RUN\\\"}}, \\\"entity\\\": {\\\"10378.1/1709248\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET\\\"}, \\\"10378.1/1709249\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET\\\"}, \\\"10378.1/1709251\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET\\\"}, \\\"10378.1/1709252\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET\\\"}, \\\"10378.1/1709260\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET\\\"}, \\\"10378.1/1709259\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"MODEL_RUN_WORKFLOW_TEMPLATE\\\", \\\"prov:type\\\": {\\\"$\\\": \\\"prov:Collection\\\", \\\"type\\\": \\\"prov:QUALIFIED_NAME\\\"}}, \\\"10378.1/1709254\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET_TEMPLATE\\\"}, \\\"10378.1/1709255\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET_TEMPLATE\\\"}, \\\"10378.1/1709256\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET_TEMPLATE\\\"}, \\\"10378.1/1709257\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET_TEMPLATE\\\"}, \\\"10378.1/1709258\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"DATASET_TEMPLATE\\\"}, \\\"10378.1/1709253\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"ENTITY\\\", \\\"item_subtype\\\": \\\"MODEL\\\"}}, \\\"agent\\\": {\\\"10378.1/1709236\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"AGENT\\\", \\\"item_subtype\\\": \\\"PERSON\\\"}, \\\"10378.1/1709247\\\": {\\\"model_run/10378.1/1709261\\\": true, \\\"item_category\\\": \\\"AGENT\\\", \\\"item_subtype\\\": \\\"ORGANISATION\\\"}}, \\\"used\\\": {\\\"_:id1\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:entity\\\": \\\"10378.1/1709248\\\"}, \\\"_:id2\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:entity\\\": \\\"10378.1/1709249\\\"}, \\\"_:id3\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:entity\\\": \\\"10378.1/1709251\\\"}, \\\"_:id4\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:entity\\\": \\\"10378.1/1709252\\\"}, \\\"_:id6\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:entity\\\": \\\"10378.1/1709253\\\"}, \\\"_:id7\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:entity\\\": \\\"10378.1/1709259\\\"}}, \\\"wasGeneratedBy\\\": {\\\"_:id5\\\": {\\\"prov:entity\\\": \\\"10378.1/1709260\\\", \\\"prov:activity\\\": \\\"10378.1/1709261\\\"}}, \\\"wasAssociatedWith\\\": {\\\"_:id8\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:agent\\\": \\\"10378.1/1709236\\\"}, \\\"_:id9\\\": {\\\"prov:activity\\\": \\\"10378.1/1709261\\\", \\\"prov:agent\\\": \\\"10378.1/1709247\\\"}}, \\\"wasAttributedTo\\\": {\\\"_:id10\\\": {\\\"prov:entity\\\": \\\"10378.1/1709260\\\", \\\"prov:agent\\\": \\\"10378.1/1709236\\\"}}, \\\"hadMember\\\": {\\\"_:id11\\\": {\\\"prov:collection\\\": \\\"10378.1/1709259\\\", \\\"prov:entity\\\": \\\"10378.1/1709254\\\"}, \\\"_:id13\\\": {\\\"prov:collection\\\": \\\"10378.1/1709259\\\", \\\"prov:entity\\\": \\\"10378.1/1709255\\\"}, \\\"_:id15\\\": {\\\"prov:collection\\\": \\\"10378.1/1709259\\\", \\\"prov:entity\\\": \\\"10378.1/1709256\\\"}, \\\"_:id17\\\": {\\\"prov:collection\\\": \\\"10378.1/1709259\\\", \\\"prov:entity\\\": \\\"10378.1/1709257\\\"}, \\\"_:id19\\\": {\\\"prov:collection\\\": \\\"10378.1/1709259\\\", \\\"prov:entity\\\": \\\"10378.1/1709258\\\"}, \\\"_:id21\\\": {\\\"prov:collection\\\": \\\"10378.1/1709259\\\", \\\"prov:entity\\\": \\\"10378.1/1709253\\\"}}, \\\"wasInfluencedBy\\\": {\\\"_:id12\\\": {\\\"prov:influencee\\\": \\\"10378.1/1709248\\\", \\\"prov:influencer\\\": \\\"10378.1/1709254\\\"}, \\\"_:id14\\\": {\\\"prov:influencee\\\": \\\"10378.1/1709249\\\", \\\"prov:influencer\\\": \\\"10378.1/1709255\\\"}, \\\"_:id16\\\": {\\\"prov:influencee\\\": \\\"10378.1/1709251\\\", \\\"prov:influencer\\\": \\\"10378.1/1709256\\\"}, \\\"_:id18\\\": {\\\"prov:influencee\\\": \\\"10378.1/1709252\\\", \\\"prov:influencer\\\": \\\"10378.1/1709257\\\"}, \\\"_:id20\\\": {\\\"prov:influencee\\\": \\\"10378.1/1709260\\\", \\\"prov:influencer\\\": \\\"10378.1/1709258\\\"}}}\",\n",
      "  \"record\": {\n",
      "    \"workflow_template_id\": \"10378.1/1709259\",\n",
      "    \"inputs\": [\n",
      "      {\n",
      "        \"dataset_template_id\": \"10378.1/1709254\",\n",
      "        \"dataset_id\": \"10378.1/1709248\",\n",
      "        \"dataset_type\": \"DATA_STORE\",\n",
      "        \"resources\": {\n",
      "          \"hourly_temperature_zarr\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_temperature_C.zarr\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"dataset_template_id\": \"10378.1/1709255\",\n",
      "        \"dataset_id\": \"10378.1/1709249\",\n",
      "        \"dataset_type\": \"DATA_STORE\",\n",
      "        \"resources\": {\n",
      "          \"relative_humidity_zarr\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_relative_humidity_percent.zarr\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"dataset_template_id\": \"10378.1/1709256\",\n",
      "        \"dataset_id\": \"10378.1/1709251\",\n",
      "        \"dataset_type\": \"DATA_STORE\",\n",
      "        \"resources\": {\n",
      "          \"wind_speed_zarr\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/baseline/AU_hourly_wind_speed_mps_updated_220224_corrected.zarr\"\n",
      "        }\n",
      "      },\n",
      "      {\n",
      "        \"dataset_template_id\": \"10378.1/1709257\",\n",
      "        \"dataset_id\": \"10378.1/1709252\",\n",
      "        \"dataset_type\": \"DATA_STORE\",\n",
      "        \"resources\": {\n",
      "          \"mcadf_zarr\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_daily_McADF_improved_uncapped.zarr\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"outputs\": [\n",
      "      {\n",
      "        \"dataset_template_id\": \"10378.1/1709258\",\n",
      "        \"dataset_id\": \"10378.1/1709260\",\n",
      "        \"dataset_type\": \"DATA_STORE\",\n",
      "        \"resources\": {\n",
      "          \"hourly_ffdi_zarr\": \"s3://nbic1-stage-shared-artifacts/nbic-stage1/weather/projected/AU_hourly_FFDI.zarr\"\n",
      "        }\n",
      "      }\n",
      "    ],\n",
      "    \"annotations\": null,\n",
      "    \"description\": \"HourlyFFDI Workflow. NBIC example. This is an example of using the FFDI workflow to register into an existing dataset.\",\n",
      "    \"associations\": {\n",
      "      \"modeller_id\": \"10378.1/1709236\",\n",
      "      \"requesting_organisation_id\": \"10378.1/1709247\"\n",
      "    },\n",
      "    \"start_time\": 1686021845,\n",
      "    \"end_time\": 1686021855\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Registering the model run \n",
    "endpoint = provenance_endpoint + \"/model_run/register_complete\"\n",
    "payload = model_run_payload\n",
    "\n",
    "# send off request\n",
    "print(\"Registering model run\")\n",
    "response = requests.post(url=endpoint, json=payload, auth=get_auth())\n",
    "\n",
    "# use helper function to check response\n",
    "registry.check_response(response=response, status_check=True)\n",
    "\n",
    "response_content = response.json()\n",
    "record_info = response_content[\"record_info\"]\n",
    "pprint_json(record_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
